{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: JUSTICE - IAM Simulation Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.util.data_loader import DataLoader\n",
    "from src.util.enumerations import *\n",
    "from src.util.model_time import TimeHorizon\n",
    "from src.model import JUSTICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Some Dummy Policy Levers\n",
    "\n",
    "JUSTICE model has two policy levers: Savings rate and Emissions Control Rate. To run the simulation version of the model, we need to feed the policy levers with some values. The range of both savings rate and emissions control rate are from 0 to 1.0 corresponding to 0% to 100%. \n",
    "\n",
    "Here we set the savings rate to the intial savings rate data of the different regions and increase it linearly to the optimal savings rate of original DICE/RICE implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lever: Fixed Savings rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 286)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_loader = DataLoader()\n",
    "\n",
    "# Instantiate the TimeHorizon class\n",
    "time_horizon = TimeHorizon(start_year=2015, end_year=2300, data_timestep=5, timestep=1)\n",
    "\n",
    "#Create a fixed savings rate\n",
    "fixed_savings_rate = np.copy(data_loader.SAVING_RATE_INIT_ARRAY).reshape(-1, 1)\n",
    "#fixed_savings_rate Validated with RICE50 for timestep 1 and 5\n",
    "\n",
    "set_year = time_horizon.model_time_horizon\n",
    "#economy.get_optimal_long_run_savings_rate() = 0.2582781457 #This needs the economy module to be instantiated\n",
    "\n",
    "for i, years in enumerate(set_year):\n",
    "    \n",
    "    t = i+1 #index starts at 0, so add 1 to get the year\n",
    "\n",
    "    if t != 1: # no need to repeat for the first year\n",
    "\n",
    "        next_rate = data_loader.SAVING_RATE_INIT_ARRAY + (0.2582781457  - data_loader.SAVING_RATE_INIT_ARRAY)*((t - 1)/(len(set_year) - 1))\n",
    "        # append to the fixed savings rate array for each year\n",
    "        fixed_savings_rate = np.column_stack((fixed_savings_rate, next_rate))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.sum(fixed_savings_rate, axis=0))\n",
    "plt.title(\"Fixed Savings Rate\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Savings Rate\")\n",
    "plt.show()\n",
    "print(fixed_savings_rate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lever: Linear Emissions Control Rate\n",
    "\n",
    "Here the emission control starts at 0, meaning no emission control and increases linearly to 100% emission control rate depending on the transistion start year and the full emission control year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#emissions control rate borrowed from emissions module\n",
    "\n",
    "#Variables to be changed/deleted later\n",
    "miu_initial = 0.0\n",
    "min_miu = 0.2 #0.0 #1.0\n",
    "min_miu_year = 2055 #9-original #8 in this model  # 2060\n",
    "max_miu = 1.0 #1.2\n",
    "max_miu_year = 2200 #38-original #37 in this model #2205\n",
    "\n",
    "t_min_miu = time_horizon.year_to_timestep(min_miu_year, timestep=1)\n",
    "t_max_miu = time_horizon.year_to_timestep(max_miu_year, timestep=1)\n",
    "\n",
    "#Initialize emissions control rate\n",
    "emissions_control_rate = np.zeros((len(data_loader.REGION_LIST), len(time_horizon.model_time_horizon)))\n",
    "\n",
    "for t in range(len(time_horizon.model_time_horizon)):\n",
    "    \n",
    "    if t < t_min_miu:       # Before time of transition\n",
    "        emissions_control_rate[:,t] = min_miu\n",
    "    elif t <= t_max_miu:   # Transition\n",
    "        # During the transition\n",
    "        emissions_control_rate[:, t] = min_miu + (max_miu - min_miu) * (t - t_min_miu)/(t_max_miu - t_min_miu)\n",
    "    else:                   # After the transition\n",
    "        emissions_control_rate[:, t] = max_miu\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(emissions_control_rate[0, :])\n",
    "plt.title(\"Emissions Control Rate\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Emissions Control\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. JUSTICE Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JUSTICE Runs on 8 SSP-RCP scenarios. The SSP-RCP scenarios can be seen with this piece of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of Scenarios from Enum\n",
    "\n",
    "for idx, scenarios in enumerate(list(Scenario.__members__.keys())):\n",
    "    print(idx, scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we initiate the model with a scenario index corresponding to a particular SSP-RCP scenario. The scenario index is from 0 to 7. The scenario index is the same as the index of the SSP-RCP scenarios in the list above.\n",
    "\n",
    "The initialization phase of JUSTICE loads all the economic and climate data, creates all the arrays to store the results and sets the initial values of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = 7\n",
    "model = JUSTICE(\n",
    "        \n",
    "        start_year = 2015,\n",
    "        end_year = 2300,\n",
    "        timestep = 1,\n",
    "        scenario =scenarios,\n",
    "        economy_type=Economy.NEOCLASSICAL,\n",
    "        damage_function_type=DamageFunction.KALKUHL,\n",
    "        abatement_type=Abatement.ENERDATA,\n",
    "        social_welfare_function=WelfareFunction.UTILITARIAN,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run\n",
    "\n",
    "The run function runs the model for a particular scenario index with the given policy lever setting. The run function returns the results of the simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(savings_rate = fixed_savings_rate, emissions_control_rate = emissions_control_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for timestep in range(len(time_horizon.model_time_horizon)):\n",
    "    \n",
    "    model.stepwise_run(savings_rate = fixed_savings_rate[:, timestep], emissions_control_rate = emissions_control_rate[:, timestep], timestep=timestep)\n",
    "    datasets = model.stepwise_evaluate(timestep=timestep)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate - SWF - and Generated Output Datasets\n",
    "\n",
    "Evaluation Phase Extracts the results from the simulation and also applies the social welfare function to compute the welfare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['net_economic_output', 'consumption', 'consumption_per_capita', 'emissions', 'regional_temperature', 'global_temperature', 'economic_damage', 'abatement_cost', 'carbon_price', 'disentangled_utility', 'welfare_utilitarian'])\n"
     ]
    }
   ],
   "source": [
    "datasets = model.evaluate() #elasticity_of_marginal_utility_of_consumption = 1.45, pure_rate_of_social_time_preference = 0.015, inequality_aversion = 0.5\n",
    "\n",
    "print(model.get_outcome_names()) # Get the list of outcomes from the simulation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = model.stepwise_evaluate(welfare_function=WelfareFunction.UTILITARIAN, elasticity_of_marginal_utility_of_consumption = 1.45, pure_rate_of_social_time_preference = 0.015, inequality_aversion = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the data from the outcome dictionary to the different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of disentangled_utility, disentangled_utility_summed, disentangled_utility_powered, welfare_utilitarian\n",
    "# Shape of discount_rate\n",
    "# (57, 286, 1)\n",
    "#(57, 286, 1001) (286, 1001) (286, 1001) (286, 1001)\n",
    "#(57, 286, 1001) (286, 1001) (286, 1001) (1001,)\n",
    "# Shape of discount_rate\n",
    "# (286, 1)\n",
    "\n",
    "net_output = datasets['net_economic_output']\n",
    "consumption = datasets['consumption'] #(57, 286, 1001)\n",
    "cpc = datasets['consumption_per_capita'] #(57, 286, 1001)\n",
    "emis = datasets['emissions'] #(57, 286, 1001)\n",
    "reg_temp = datasets['regional_temperature']\n",
    "temp = datasets['global_temperature'] # (286, 1001)\n",
    "damages = datasets['economic_damage'] #(57, 286, 1001)\n",
    "abatecost = datasets['abatement_cost'] #(57, 286, 1001)\n",
    "dis_util = datasets['disentangled_utility'] #(57, 286, 1001)\n",
    "util = datasets['welfare_utilitarian'] # (286, 1001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = reg_temp[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize\n",
    "\n",
    "We can visualize the timeseries of the different outcomes that we extracted in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create list of all the data arrays\n",
    "data_list = [net_output, cpc, emis, dis_util, damages, abatecost]\n",
    "titles = ['Net Economic Output', 'Consumption per Capita', 'Emissions', 'Disaggregated Utility', 'Economic Damages', 'Abatement Cost']\n",
    "\n",
    "region_index = 0\n",
    "\n",
    "# Create a figure with 2 rows and 3 columns\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Flatten the axs array to iterate over it\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Iterate over the data arrays and plot them\n",
    "for i, data in enumerate(data_list):\n",
    "    # Select the region based on region_index\n",
    "    region_data = data[region_index, :, :]\n",
    "    \n",
    "    # Create a line plot for each scenario\n",
    "    for j in range(region_data.shape[1]):\n",
    "        sns.lineplot(x=time_horizon.model_time_horizon, y=region_data[:, j], ax=axs[i])\n",
    "    \n",
    "    # Set the title and axis labels\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].set_xlabel('Year')\n",
    "    axs[i].set_ylabel('Value')\n",
    "    \n",
    "# Remove the unused subplots\n",
    "for i in range(len(data_list), len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "# Adjust the layout and spacing\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the data for each scenario\n",
    "scenario_data = {}\n",
    "\n",
    "\n",
    "for idx, scenarios in enumerate(list(Scenario)):\n",
    "    print(idx, scenarios)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = JUSTICE(\n",
    "        \n",
    "        start_year = 2015,\n",
    "        end_year = 2300,\n",
    "        timestep = 1,\n",
    "        scenario =scenarios,\n",
    "        economy_type=Economy.NEOCLASSICAL,\n",
    "        damage_function_type=DamageFunction.KALKUHL,\n",
    "        abatement_type=Abatement.ENERDATA,\n",
    "    )\n",
    "    \n",
    "    # Run the model\n",
    "    model.run(savings_rate = fixed_savings_rate, emissions_control_rate = emissions_control_rate)\n",
    "\n",
    "    # elasticity_of_marginal_utility_of_consumption,\n",
    "    # pure_rate_of_social_time_preference,\n",
    "    # inequality_aversion,\n",
    "    # Evaluate the model\n",
    "    scenario_data[scenarios] = model.evaluate(welfare_function=WelfareFunction.UTILITARIAN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Codes after this point is for testing purpose. Not example codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMA Workbench Tests\n",
    "\n",
    "Codes for Uncertainty analysis and Multiobjective optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.analyzer import perform_exploratory_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_exploratory_analysis(number_of_experiments=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import ema_logging, load_results\n",
    "fn = \"./data/output/results_open_exploration_2_95th\"\n",
    "results = load_results(fn)\n",
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments.columns\n",
    "# Select columns of interest ['elasticity_of_marginal_utility_of_consumption', 'inequality_aversion',  'pure_rate_of_social_time_preference', 'ssp_rcp_scenario', 'scenario','policy']\n",
    "experiments = experiments[['elasticity_of_marginal_utility_of_consumption', 'inequality_aversion',  'pure_rate_of_social_time_preference', 'ssp_rcp_scenario', 'scenario','policy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes.keys()\n",
    "# global_temperature = outcomes['global_temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_array = outcomes['disentangled_utility']\n",
    "\n",
    "# compute the mean across the scenarios\n",
    "mean_arr = np.mean(outcomes_array, axis=0)\n",
    "\n",
    "# let's define n as the amount of close scenarios you'd like to select\n",
    "n = 10\n",
    "\n",
    "# compute the difference between each scenario and the mean\n",
    "diff = outcomes_array - mean_arr\n",
    "\n",
    "# compute the \"distance\" to the mean\n",
    "distances = np.linalg.norm(diff, axis=(1,2))\n",
    "\n",
    "# get the indices of the n scenarios with smallest distances\n",
    "# here, np.argsort returns the indices that would sort the distances\n",
    "# we are interested in the first n of these (the ones with smallest distance)\n",
    "closest_indices = np.argsort(distances)[:n]\n",
    "\n",
    "print(f\"The scenarios that are closest to the mean are at indices {closest_indices} out of 2000.\")\n",
    "\n",
    "# # compute the difference between each scenario and the mean\n",
    "# diff = outcomes_array - mean_arr\n",
    "\n",
    "# # Now we want to compute the \"distance\" to the mean, we can use Euclidean distance as a measure\n",
    "# distances = np.linalg.norm(diff, axis=(1,2))\n",
    "\n",
    "# # the scenario that represents the mean is the one with the smallest distance\n",
    "# index = np.argmin(distances)\n",
    "\n",
    "# print(f\"The scenario that represents the mean is at index {index} out of 2000.\")\n",
    "\n",
    "# # sum the utility for all regions\n",
    "# # outcomes_array = np.sum(outcomes_array, axis=1)\n",
    "# # mean_util = np.mean(outcomes_array, axis=0)\n",
    "# median_util = np.median(outcomes_array, axis=0)\n",
    "# #95th percentile\n",
    "# p95_util = np.percentile(outcomes_array, 95, axis=0)\n",
    "# #5th percentile\n",
    "# p5_util = np.percentile(outcomes_array, 5, axis=0)\n",
    "\n",
    "# # Sum the utility for all regions\n",
    "# mean_util = np.sum(mean_util, axis=0)\n",
    "# median_util = np.sum(median_util, axis=0)\n",
    "# #95th percentile\n",
    "# p95_util = np.sum(p95_util, axis=0)\n",
    "# #5th percentile\n",
    "# p5_util = np.sum(p5_util, axis=0)\n",
    "\n",
    "\n",
    "# Plot the mean, median, 5th and 95th percentile. Array is of shape (57, 286). 286 are the timesteps. 57 are the scenarios\n",
    "# plt.plot(mean_util, label='Mean')\n",
    "# plt.plot(median_util, label='Median')\n",
    "# plt.plot(p95_util, label='95th Percentile')\n",
    "# plt.plot(p5_util, label='5th Percentile')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Utility')\n",
    "# plt.title('Utility over Time')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "from src.data_loader import DataLoader\n",
    "import pandas as pd\n",
    "data_loader = DataLoader()\n",
    "\n",
    "region_list = data_loader.REGION_LIST\n",
    "region_list[54] # US\n",
    "region_list[43] #Sub saharan \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Analysis Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined arrays\n",
    "import pickle\n",
    "import numpy as np\n",
    "with open('./data/output/temp_combined_1000.pkl', 'rb') as f:\n",
    "    combined_temp = pickle.load(f)\n",
    "with open('./data/output/damages_combined_1000.pkl', 'rb') as f:\n",
    "    combined_damages = pickle.load(f)\n",
    "with open('./data/output/dis_util_combined_1000.pkl', 'rb') as f:\n",
    "    combined_dis_util = pickle.load(f)\n",
    "with open('./data/output/experiments_combined_1000.pkl', 'rb') as f:\n",
    "    combined_experiments = pickle.load(f)\n",
    "\n",
    "# Load welfare_utilitarian_regional_combined_1000\n",
    "with open('./data/output/welfare_utilitarian_regional_combined_1000.pkl', 'rb') as f:\n",
    "    welfare_utilitarian_regional_combined_1000 = pickle.load(f)\n",
    "    welfare_utilitarian_regional_combined_1000 = welfare_utilitarian_regional_combined_1000.T\n",
    "\n",
    "# Load welfare_utilitarian_combined_1000\n",
    "with open('./data/output/welfare_utilitarian_combined_1000.pkl', 'rb') as f:\n",
    "    welfare_utilitarian_combined_1000 = pickle.load(f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Load the data\n",
    "temperature_array = np.load(\"./data/output/temperature_array.npy\", allow_pickle=True)\n",
    "data_array = np.load(\"./data/output/damages_array.npy\", allow_pickle=True)\n",
    "disentangled_utility = np.load(\"./data/output/disentangled_utility.npy\", allow_pickle=True)\n",
    "experiment_array = np.load(\"./data/output/experiment_array.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in input/solved_RICE50_data folder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "solved_damages = np.load(\"./data/input/solved_RICE50_data/solved_damages.npy\", allow_pickle=True)\n",
    "solved_emissions_control = np.load(\"./data/input/solved_RICE50_data/solved_emissions_control.npy\", allow_pickle=True)\n",
    "solved_savings_rate = np.load(\"./data/input/solved_RICE50_data/solved_savings_rate.npy\", allow_pickle=True)\n",
    "solved_TATM = np.load(\"./data/input/solved_RICE50_data/solved_TATM.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_time import TimeHorizon\n",
    "\n",
    "# Instantiate the TimeHorizon class\n",
    "time_horizon = TimeHorizon(start_year=2015, end_year=2300, data_timestep=5, timestep=1)\n",
    "from analysis.output_data_processor import interpolator\n",
    "\n",
    "\n",
    "interpolated_emissions_control = interpolator(solved_emissions_control, time_horizon.data_time_horizon, time_horizon.model_time_horizon)\n",
    "interpolated_savings_rate = interpolator(solved_savings_rate, time_horizon.data_time_horizon, time_horizon.model_time_horizon)\n",
    "interpolated_TATM = interpolator(solved_TATM, time_horizon.data_time_horizon, time_horizon.model_time_horizon)\n",
    "interpolated_damages = interpolator(solved_damages, time_horizon.data_time_horizon, time_horizon.model_time_horizon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save interpolated emissions control rate and interpolated savings rate as npy\n",
    "\n",
    "np.save('./data/input/solved_RICE50_data/interpolated_emissions_control.npy', interpolated_emissions_control)\n",
    "np.save('./data/input/solved_RICE50_data/interpolated_savings_rate.npy', interpolated_savings_rate)\n",
    "np.save('./data/input/solved_RICE50_data/RICE50_interpolated_TATM.npy', interpolated_TATM)\n",
    "np.save('./data/input/solved_RICE50_data/RICE50_interpolated_damages.npy', interpolated_damages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Code Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Load interpolated damages\n",
    "interpolated_damages = np.load(\"./data/input/solved_RICE50_data/RICE50_interpolated_damages.npy\", allow_pickle=True) # Shape (5, 57, 286)\n",
    "# Load damages array\n",
    "damages_array = np.load(\"./data/output/damages_array.npy\", allow_pickle=True) # Shape (8000, 57, 286)\n",
    "\n",
    "# Load the TATM interpolated\n",
    "interpolated_TATM = np.load(\"./data/input/solved_RICE50_data/RICE50_interpolated_TATM.npy\", allow_pickle=True) # Shape (5, 286)\n",
    "# Load temperature array\n",
    "temperature_array = np.load(\"./data/output/temperature_array.npy\", allow_pickle=True) # Shape (8000, 286)\n",
    "\n",
    "# Load experiment array\n",
    "experiment_array = np.load(\"./data/output/experiment_array.npy\", allow_pickle=True) # Shape (8000, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert experiment array to dataframe and add column names\n",
    "import pandas as pd\n",
    "experiment_array = pd.DataFrame(experiment_array, columns=\n",
    "            [\n",
    "                \"elasticity_of_marginal_utility_of_consumption\",\n",
    "                \"inequality_aversion\",\n",
    "                \"pure_rate_of_social_time_preference\",\n",
    "                \"ssp_rcp_scenario\",\n",
    "                \"scenario\",\n",
    "                \"policy\",\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.enumerations import get_economic_scenario\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Select the temperature array scenario from index from 4000-6000\n",
    "mean_temperature_array = temperature_array #temperature_array[4000:6000, :]\n",
    "mean_experiment_array = experiment_array #experiment_array.iloc[4000:6000, :]\n",
    "\n",
    "#Reset index\n",
    "# mean_temperature_array = pd.DataFrame(mean_temperature_array).reset_index(drop=True)\n",
    "# mean_experiment_array = mean_experiment_array.reset_index(drop=True)\n",
    "\n",
    "# Assuming experiment_array and temperature_array here are represented as DataFrame and np.ndarray.\n",
    "\n",
    "scenario_indexes = []\n",
    "# get the indexes of rows for all the scenarios from 0 to 7\n",
    "for x in range(8):\n",
    "    scenario_indexes.append(\n",
    "        mean_experiment_array[mean_experiment_array['ssp_rcp_scenario'] == x].index.tolist()\n",
    "    )\n",
    "\n",
    "# Assume your temperature array is a numpy ndarray\n",
    "# Filter out temperature array using the list of indexes\n",
    "temperature_array_sorted = {}\n",
    "\n",
    "for i, indexes in enumerate(scenario_indexes):\n",
    "    temperature_array_sorted[i] = np.array([mean_temperature_array[j] for j in indexes])\n",
    "\n",
    "# Use scenario_indexes to filter out experiment_array\n",
    "experiment_array_sorted = {}\n",
    "\n",
    "for i, indexes in enumerate(scenario_indexes):\n",
    "    experiment_array_sorted[i] = mean_experiment_array.loc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort damages_array\n",
    "\n",
    "#damages_array_summed = np.sum(damages_array, axis=1)\n",
    "\n",
    "damages_array_sorted = {}\n",
    "\n",
    "for i, indexes in enumerate(scenario_indexes):\n",
    "    damages_array_sorted[i] = np.array([damages_array[j] for j in indexes])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = experiment_array_sorted[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature array for each scenario\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(8):\n",
    "    plt.plot(temperature_array_sorted[i].mean(axis=0), label=get_economic_scenario(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_economic_scenario(7))\n",
    "# Use list of years as column labels for the combined_temp array\n",
    "#temperature_array = pd.DataFrame(temperature_array, columns=list_of_years)\n",
    "\n",
    "# df = pd.DataFrame(temperature_array)\n",
    "# df = df.T\n",
    "# for i in range(len(df.columns)):\n",
    "    \n",
    "#     sns.lineplot(data=df.iloc[:,i],palette=\"tab10\", linewidth=0.5, alpha=0.5)\n",
    "# sns.lineplot(data=df.iloc[:,0])\n",
    "# plt.title(\"Temperature Array\")\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Temperature\")\n",
    "# plt.show()\n",
    "\n",
    "    #plt.plot(rice50_temp.iloc[i, :], label=f'SSP {i+1}')\n",
    "\n",
    "# Label the percentiles\n",
    "# plt.text(2300, 0.5, '0th percentile', color='black')\n",
    "# plt.text(2300, 2.5, '5th percentile', color='black')\n",
    "# plt.text(2300, 3.5, '25th percentile', color='black')\n",
    "# plt.text(2300, 4.5, '75th percentile', color='black')\n",
    "# plt.text(2300, 5.5, '95th percentile', color='black')\n",
    "# plt.text(2300, 11.5, '100th percentile', color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dictionary to hold temperature arrays separated by SSPs\n",
    "temperature_array_sorted_by_ssp = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "# iterate over temperature_array_sorted dictionary\n",
    "for scenario in temperature_array_sorted:\n",
    "    # get the corresponding SSP for scenario\n",
    "    ssp = get_economic_scenario(scenario)\n",
    "    # append the temperature array for scenario to the appropriate SSP key in temperature_array_sorted_by_ssp\n",
    "    temperature_array_sorted_by_ssp[ssp].extend(temperature_array_sorted[scenario])\n",
    "\n",
    "# converting lists in the dictionary to numpy arrays\n",
    "for ssp in temperature_array_sorted_by_ssp:\n",
    "    temperature_array_sorted_by_ssp[ssp] = np.array(temperature_array_sorted_by_ssp[ssp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean of ssps in temperature_array_sorted_by_ssp\n",
    "for ssp in temperature_array_sorted_by_ssp:\n",
    "    plt.plot(np.mean(temperature_array_sorted_by_ssp[ssp], axis=0), label=f'SSP {ssp}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature array dataframe of shape (8000, 286) where 8000 are the scenarios and 286 are the timesteps\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.model_time import TimeHorizon\n",
    "\n",
    "\n",
    "time_horizon = TimeHorizon(start_year=2015, end_year=2300, data_timestep=5, timestep=1)\n",
    "list_of_years = time_horizon.model_time_horizon\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "#plt.figure(figsize=(15, 8))\n",
    "last_idx = -1\n",
    "# colors = ['blue', 'green', 'yellow', 'red', 'violet']\n",
    "colors = ['red', 'orange', 'green', 'blue', 'indigo']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "rice50_temp = pd.DataFrame(interpolated_TATM, columns=list_of_years)\n",
    "\n",
    "# Loop through each ssp in your sorted data\n",
    "for i in range(8):\n",
    "    # calculate 5th and 95th percentiles\n",
    "    p_5 = np.percentile(temperature_array_sorted[i], 5, axis=0)\n",
    "    p_95 = np.percentile(temperature_array_sorted[i], 95, axis=0)\n",
    "\n",
    "    idx = get_economic_scenario(i)\n",
    "    \n",
    "    # Plot percentiles as bands\n",
    "    ax.fill_between(list_of_years, p_5, p_95, color=colors[idx], alpha=0) #.2\n",
    "\n",
    "    \n",
    "    # Plot the interpolated TATM for each scenario\n",
    "    if last_idx != idx:\n",
    "        sns.lineplot(data=rice50_temp.iloc[idx, :], color=colors[idx], label=f'SSP {idx+1}', ax=ax)\n",
    "\n",
    "    last_idx = idx\n",
    "\n",
    "\n",
    "# Access the current Axes instance on the current figure:\n",
    "ax = plt.gca()\n",
    "\n",
    "# Remove top and right border\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "  \n",
    "# Remove top and right ticks\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# Add labels, legend and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature Rise')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.enumerations import get_economic_scenario, Scenario\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.model_time import TimeHorizon\n",
    "\n",
    "\n",
    "\n",
    "ssp_rcp_string_list = [\"SSP1-RCP1.9\", \"SSP1-RCP2.6\", \"SSP2-RCP4.5\", \"SSP3-RCP7.0\", \"SSP4-RCP3.4\", \"SSP4-RCP6.0\", \"SSP5-RCP3.4-overshoot\", \"SSP5-RCP8.5\"]\n",
    "\n",
    "scenario = list(Scenario)\n",
    "# Color Mapping\n",
    "colors = ['red', 'orange', 'green', 'blue', 'indigo']\n",
    "\n",
    "# Time Horizon Setup\n",
    "time_horizon = TimeHorizon(start_year=2015, end_year=2300, data_timestep=5, timestep=1)\n",
    "list_of_years = time_horizon.model_time_horizon\n",
    "\n",
    "rice50_temp = pd.DataFrame(interpolated_TATM, columns=list_of_years)\n",
    "\n",
    "# Create subplots in grid of 4 rows and 2 columns\n",
    "fig, axs = plt.subplots(2, 4, figsize=(25, 12))\n",
    "\n",
    "# Reshape axs to 1D for easy iteration\n",
    "axs = axs.ravel()\n",
    "\n",
    "# find overall min and max temperatures (5th and 95th percentile respectively) amongst all data\n",
    "global_min = np.min([np.percentile(temperature_array_sorted[i], 5, axis=0) for i in range(8)])\n",
    "global_max = np.max([np.percentile(temperature_array_sorted[i], 95, axis=0) for i in range(8)])\n",
    "\n",
    "for i in range(8):\n",
    "    # calculate 5th and 95th percentiles\n",
    "    p_5 = np.percentile(temperature_array_sorted[i], 5, axis=0)\n",
    "    p_95 = np.percentile(temperature_array_sorted[i], 95, axis=0)\n",
    "\n",
    "    # Get the economic scenario corresponding to the index\n",
    "    idx = get_economic_scenario(i)\n",
    "\n",
    "    # Plot percentiles as bands\n",
    "    axs[i].fill_between(list_of_years, p_5, p_95, color=colors[idx], alpha=0.2)\n",
    "\n",
    "\n",
    "    # Plot\n",
    "    sns.lineplot(data=rice50_temp.iloc[idx, :], color=colors[idx], ax=axs[i])\n",
    "\n",
    "    # Styling each subplot\n",
    "    axs[i].spines['right'].set_visible(False)\n",
    "    axs[i].spines['top'].set_visible(False)\n",
    "    axs[i].xaxis.set_ticks_position('bottom')\n",
    "    axs[i].yaxis.set_ticks_position('left')\n",
    "\n",
    "    # axs[i].set_xlabel('Year')\n",
    "    axs[i].set_ylabel('Temperature Rise')\n",
    "    axs[i].legend([f'SSP {idx+1}'], loc='upper left')\n",
    "    # Set title for each subplot\n",
    "    axs[i].set_title(ssp_rcp_string_list[i]) #(scenario[i].value[2])\n",
    "    axs[i].title.set_size(20)\n",
    "    axs[i].set_ylim(global_min, global_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.enumerations import get_economic_scenario, Scenario\n",
    "scenario = list(Scenario)\n",
    "scenario[0].value[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature array dataframe of shape (8000, 286) where 8000 are the scenarios and 286 are the timesteps\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.model_time import TimeHorizon\n",
    "\n",
    "time_horizon = TimeHorizon(start_year=2015, end_year=2300, data_timestep=5, timestep=1)\n",
    "list_of_years = time_horizon.model_time_horizon\n",
    "\n",
    "\n",
    "# Setting style and size\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Calculate percentiles and median\n",
    "p_0 = np.percentile(temperature_array, 0, axis=0)\n",
    "p_5 = np.percentile(temperature_array, 5, axis=0)\n",
    "p_25 = np.percentile(temperature_array, 25, axis=0)\n",
    "p_75 = np.percentile(temperature_array, 75, axis=0)\n",
    "p_95 = np.percentile(temperature_array, 95, axis=0)\n",
    "p_100 = np.percentile(temperature_array, 100, axis=0)\n",
    "median = np.median(temperature_array, axis=0)\n",
    "\n",
    "# Plot percentiles as bands\n",
    "plt.fill_between(temperature_array.columns, p_0, p_100, color='red', alpha=0.3)\n",
    "plt.fill_between(temperature_array.columns, p_5, p_95, color='red', alpha=0.2)\n",
    "plt.fill_between(temperature_array.columns, p_25, p_75, color='red', alpha=0.4)\n",
    "\n",
    "# Plot median\n",
    "plt.plot(temperature_array.columns, median, color='red')\n",
    "\n",
    "# Use the list of years as x-axis and the interpolated TATM for each scenario as y-axis\n",
    "rice50_temp = pd.DataFrame(interpolated_TATM, columns=list_of_years)\n",
    "# Overlay the interpolated TATM for all 5 scenarios. TATM shape (5, 286) Each scenario with a different color and with legend\n",
    "for i in range(rice50_temp.shape[0]):\n",
    "    # Use a list of colors\n",
    "    colors = ['blue', 'green', 'black', 'purple', 'brown']\n",
    "    sns.lineplot(data=rice50_temp.iloc[i, :], color=colors[i], label=f'SSP {i+1}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Access the current Axes instance on the current figure:\n",
    "ax = plt.gca()\n",
    "\n",
    "# Remove top and right border\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "  \n",
    "# Remove top and right ticks\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature Rise')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# plt.title('Time series plot of Atmospheric Temperature Rise')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for damages array\n",
    "# Setting style and size\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "damages_array_summed = np.sum(damages_array, axis=1)\n",
    "damages_array_summed = pd.DataFrame(damages_array_summed, columns=list_of_years)\n",
    "\n",
    "\n",
    "# Calculate percentiles and median\n",
    "p_0 = np.min(damages_array_summed, axis=0)\n",
    "#p_0 = np.percentile(damages_array_summed, 0, axis=0)\n",
    "# p_5 = np.percentile(damages_array_summed, 5, axis=0)\n",
    "# p_25 = np.percentile(damages_array_summed, 25, axis=0)\n",
    "# p_75 = np.percentile(damages_array_summed, 75, axis=0)\n",
    "# p_95 = np.percentile(damages_array_summed, 95, axis=0)\n",
    "p_100 = np.max(damages_array_summed, axis=0)\n",
    "#p_100 = np.percentile(damages_array_summed, 100, axis=0)\n",
    "median = np.median(damages_array_summed, axis=0)\n",
    "\n",
    "# Plot percentiles as bands\n",
    "plt.fill_between(damages_array_summed.columns, p_0, p_100, color='green', alpha=0.3)\n",
    "# plt.fill_between(damages_array_summed.columns, p_5, p_95, color='green', alpha=0.2)\n",
    "# plt.fill_between(damages_array_summed.columns, p_25, p_75, color='green', alpha=0.4)\n",
    "\n",
    "# Plot median\n",
    "plt.plot(damages_array_summed.columns, median, color='green')\n",
    "\n",
    "# Sum the damages for all regions\n",
    "rice50_damages = np.sum(interpolated_damages, axis=1)\n",
    "# Use the list of years as x-axis and the interpolated damages for each scenario as y-axis\n",
    "rice50_damages = pd.DataFrame(rice50_damages, columns=list_of_years)\n",
    "\n",
    "\n",
    "# Overlay the interpolated damages for all 5 scenarios. Damages shape (5, 286) Each scenario with a different color and with legend\n",
    "for i in range(rice50_damages.shape[0]):\n",
    "    # Use a list of colors\n",
    "    colors = ['blue', 'red', 'black', 'purple', 'brown']\n",
    "    sns.lineplot(data=rice50_damages.iloc[i, :], color=colors[i], label=f'SSP {i+1}')\n",
    "\n",
    "# Access the current Axes instance on the current figure:\n",
    "ax = plt.gca()\n",
    "\n",
    "# Remove top and right border\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "  \n",
    "# Remove top and right ticks\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Economic Damage')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# plt.title('Time series plot of Atmospheric Temperature Rise')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature array dataframe of shape (8000, 286) where 8000 are the scenarios and 286 are the timesteps\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.model_time import TimeHorizon\n",
    "\n",
    "\n",
    "time_horizon = TimeHorizon(start_year=2015, end_year=2300, data_timestep=5, timestep=1)\n",
    "list_of_years = time_horizon.model_time_horizon\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "#plt.figure(figsize=(15, 8))\n",
    "last_idx = -1\n",
    "# colors = ['blue', 'green', 'yellow', 'red', 'violet']\n",
    "colors = ['red', 'orange', 'green', 'blue', 'indigo']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "#rice50_temp = pd.DataFrame(interpolated_TATM, columns=list_of_years)\n",
    "rice50_damages = np.sum(interpolated_damages, axis=1)\n",
    "# Use the list of years as x-axis and the interpolated damages for each scenario as y-axis\n",
    "rice50_damages = pd.DataFrame(rice50_damages, columns=list_of_years)\n",
    "\n",
    "# Loop through each ssp in your sorted data\n",
    "for i in range(8):\n",
    "    # calculate 5th and 95th percentiles\n",
    "    p_5 = np.percentile(np.sum(damages_array_sorted[i], axis=1), 5, axis=0)\n",
    "    p_95 = np.percentile(np.sum(damages_array_sorted[i], axis=1), 95, axis=0)\n",
    "\n",
    "    idx = get_economic_scenario(i)\n",
    "    \n",
    "    # Plot percentiles as bands\n",
    "    ax.fill_between(list_of_years, p_5, p_95, color=colors[idx], alpha=0.2)\n",
    "\n",
    "    \n",
    "    # Plot the interpolated TATM for each scenario\n",
    "    if last_idx != idx:\n",
    "        sns.lineplot(data=rice50_damages.iloc[idx, :], color=colors[idx], label=f'SSP {idx+1}', ax=ax)\n",
    "\n",
    "    last_idx = idx\n",
    "\n",
    "\n",
    "# Access the current Axes instance on the current figure:\n",
    "ax = plt.gca()\n",
    "\n",
    "# Remove top and right border\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "  \n",
    "# Remove top and right ticks\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# Add labels, legend and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Economic Damage Trillion $')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.enumerations import get_economic_scenario, Scenario\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.model_time import TimeHorizon\n",
    "\n",
    "\n",
    "\n",
    "ssp_rcp_string_list = [\"SSP1-RCP1.9\", \"SSP1-RCP2.6\", \"SSP2-RCP4.5\", \"SSP3-RCP7.0\", \"SSP4-RCP3.4\", \"SSP4-RCP6.0\", \"SSP5-RCP3.4-overshoot\", \"SSP5-RCP8.5\"]\n",
    "\n",
    "scenario = list(Scenario)\n",
    "# Color Mapping\n",
    "colors = ['red', 'orange', 'green', 'blue', 'indigo']\n",
    "\n",
    "# Time Horizon Setup\n",
    "time_horizon = TimeHorizon(start_year=2015, end_year=2300, data_timestep=5, timestep=1)\n",
    "list_of_years = time_horizon.model_time_horizon\n",
    "\n",
    "# rice50_temp = pd.DataFrame(interpolated_TATM, columns=list_of_years)\n",
    "# damages_array_summed = np.sum(damages_array, axis=1)\n",
    "# damages_array_summed = pd.DataFrame(damages_array_summed, columns=list_of_years)\n",
    "# Sum the damages for all regions\n",
    "rice50_damages = np.sum(interpolated_damages, axis=1)\n",
    "# Use the list of years as x-axis and the interpolated damages for each scenario as y-axis\n",
    "rice50_damages = pd.DataFrame(rice50_damages, columns=list_of_years)\n",
    "\n",
    "# Create subplots in grid of 4 rows and 2 columns\n",
    "fig, axs = plt.subplots(2, 4, figsize=(25, 12))\n",
    "\n",
    "# Reshape axs to 1D for easy iteration\n",
    "axs = axs.ravel()\n",
    "\n",
    "# find overall min and max temperatures (5th and 95th percentile respectively) amongst all data\n",
    "global_min = np.min([np.percentile(np.sum(damages_array_sorted[i], axis=1), 5, axis=0) for i in range(8)])\n",
    "global_max = np.max([np.percentile(np.sum(damages_array_sorted[i], axis=1), 95, axis=0) for i in range(8)])\n",
    "\n",
    "for i in range(8):\n",
    "    # calculate 5th and 95th percentiles\n",
    "    p_5 = np.percentile(np.sum(damages_array_sorted[i], axis=1), 5, axis=0)\n",
    "    p_95 = np.percentile(np.sum(damages_array_sorted[i], axis=1), 95, axis=0)\n",
    "\n",
    "    # Get the economic scenario corresponding to the index\n",
    "    idx = get_economic_scenario(i)\n",
    "\n",
    "    # Plot percentiles as bands\n",
    "    axs[i].fill_between(list_of_years, p_5, p_95, color=colors[idx], alpha=0.2)\n",
    "\n",
    "\n",
    "    # Plot\n",
    "    sns.lineplot(data=rice50_damages.iloc[idx, :], color=colors[idx], ax=axs[i])\n",
    "\n",
    "    # Styling each subplot\n",
    "    axs[i].spines['right'].set_visible(False)\n",
    "    axs[i].spines['top'].set_visible(False)\n",
    "    axs[i].xaxis.set_ticks_position('bottom')\n",
    "    axs[i].yaxis.set_ticks_position('left')\n",
    "\n",
    "    # axs[i].set_xlabel('Year')\n",
    "    axs[i].set_ylabel('Economic Damages Trillion $')\n",
    "    axs[i].legend([f'SSP {idx+1}'], loc='upper left')\n",
    "    # Set title for each subplot\n",
    "    axs[i].set_title(ssp_rcp_string_list[i]) #(scenario[i].value[2])\n",
    "    # Set title font size\n",
    "    axs[i].title.set_size(20)\n",
    "\n",
    "    axs[i].set_ylim(global_min, global_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.output_data_processor import calculate_welfare\n",
    "\n",
    "from src.model_time import TimeHorizon\n",
    "\n",
    "# Instantiate the TimeHorizon class\n",
    "time_horizon = TimeHorizon(start_year=2015, end_year=2300, data_timestep=5, timestep=1)\n",
    "\n",
    "timestep_list = np.arange(\n",
    "    0, len(time_horizon.model_time_horizon), time_horizon.timestep\n",
    ")\n",
    "\n",
    "welfare_utilitarian = np.zeros((experiment_array.shape[0]))\n",
    "welfare_utilitarian_regional = np.zeros((57, experiment_array.shape[0]))\n",
    "\n",
    "for i in range(experiment_array.shape[0]):\n",
    "\n",
    "    welfare_utilitarian_regional[:,i], welfare_utilitarian[i] = calculate_welfare(experiment_array[i], disentangled_utility[i], time_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_time import TimeHorizon\n",
    "from analysis.output_data_processor import calculate_welfare\n",
    "\n",
    "# Instantiate the TimeHorizon class\n",
    "time_horizon = TimeHorizon(start_year=2015, end_year=2300, data_timestep=5, timestep=1)\n",
    "\n",
    "# Convert experiments_array dataframe to numpy array\n",
    "# experiments = experiment_array #np.array(experiment_array)\n",
    "\n",
    "welfare_utilitarian = np.zeros((experiment_array.shape[0]))\n",
    "welfare_utilitarian_regional = np.zeros((57, experiment_array.shape[0]))\n",
    "\n",
    "for i in range(experiment_array.shape[0]):\n",
    "\n",
    "    welfare_utilitarian_regional[:,i], welfare_utilitarian[i] = calculate_welfare(experiment_array[i], disentangled_utility[i], time_horizon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot welfare_utilitarian of shape (60000, )\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot distribution of welfare_utilitarian\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot distribution of welfare_utilitarian\n",
    "\n",
    "sns.histplot(welfare_utilitarian, kde=True, bins=100, color='red')\n",
    "plt.xlabel('Welfare Utilitarian')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Welfare Utilitarian')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "from src.data_loader import DataLoader\n",
    "import pandas as pd\n",
    "data_loader = DataLoader()\n",
    "\n",
    "region_list = data_loader.REGION_LIST\n",
    "\n",
    "# Convert region list to a dataframe\n",
    "region_list = pd.DataFrame(region_list)\n",
    "#region_list.iloc[54] # US\n",
    "# region_list[54] # US\n",
    "# region_list[43] #Sub saharan \n",
    "region_list[0].values\n",
    "\n",
    "# Get the list of regions as byte strings\n",
    "regions_byte = region_list[0].values\n",
    "\n",
    "# Decode byte strings to normal strings\n",
    "regions_str = [region.decode('utf-8') for region in regions_byte]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to drop the nan and inf values from the welfare_utilitarian array\n",
    "\n",
    "regional_welfare = welfare_utilitarian_regional.T\n",
    "\n",
    "# filtered_index = filtered_df.dropna()\n",
    "# filtered_index = filtered_index.index\n",
    "\n",
    "# filtered_experiments = combined_experiments[filtered_index]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Identify the indices where nan or inf values present\n",
    "indices = np.where(np.isnan(regional_welfare) | np.isinf(regional_welfare) | (regional_welfare<-100000) | (regional_welfare>100000))\n",
    "\n",
    "# Get the unique row indices\n",
    "unique_row_indices = np.unique(indices[0])\n",
    "\n",
    "# Drop those rows from the array\n",
    "regional_welfare = np.delete(regional_welfare, unique_row_indices, axis=0)\n",
    "\n",
    "# Assuming `experiments_df` is your DataFrame, drop the corresponding rows from the DataFrame\n",
    "experiments_df = experiment_array.drop(unique_row_indices)\n",
    "\n",
    "print(regional_welfare.shape)\n",
    "print(experiments_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter welfare_utilitarian for values between -100000 and 100000 and nan and inf values\n",
    "\n",
    "global_welfare = welfare_utilitarian\n",
    "\n",
    "# Identify the indices where nan or inf values present\n",
    "indices = np.where(np.isnan(global_welfare) | np.isinf(global_welfare) | (global_welfare<-100000) | (global_welfare>100000))\n",
    "\n",
    "# Get the unique row indices\n",
    "unique_row_indices = np.unique(indices[0])\n",
    "\n",
    "# Drop those rows from the array\n",
    "global_welfare = np.delete(global_welfare, unique_row_indices, axis=0)\n",
    "\n",
    "# Assuming `experiments_df` is your DataFrame, drop the corresponding rows from the DataFrame\n",
    "experiments_df = experiment_array.drop(unique_row_indices)\n",
    "\n",
    "print(global_welfare.shape)\n",
    "print(experiments_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_idx = 43\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "filtered_outcomes = {}\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "# Create a empty dataframe to store the feature scores of shape 57, 3\n",
    "scores = pd.DataFrame(np.zeros((57, 4)), columns=['elasticity_of_marginal_utility_of_consumption', 'inequality_aversion', 'pure_rate_of_social_time_preference', 'ssp_rcp_scenario'])\n",
    "# Loop throught he regions_str list\n",
    "\n",
    "for region_idx in range(57):\n",
    "    print(region_idx)\n",
    "    # Create a dictionary to store the filtered outcomes\n",
    "    filtered_outcomes[regions_str[region_idx]] = regional_welfare[:,region_idx]\n",
    "    filtered_outcomes[regions_str[region_idx]] = regional_welfare[:,region_idx]\n",
    "    # Suppress the warnings\n",
    "\n",
    "\n",
    "    scores = feature_scoring.get_feature_scores_all(experiments_df.iloc[:, :4], filtered_outcomes)\n",
    "    \n",
    "sns.heatmap(scores, annot=True, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "filtered_outcomes_global = {}   \n",
    "\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "# Create a empty dataframe to store the feature scores of shape 57, 3\n",
    "global_scores = pd.DataFrame(np.zeros((57, 4)), columns=['elasticity_of_marginal_utility_of_consumption', 'inequality_aversion', 'pure_rate_of_social_time_preference', 'ssp_rcp_scenario'])\n",
    "\n",
    "filtered_outcomes_global['Global'] = global_welfare\n",
    "\n",
    "global_scores = feature_scoring.get_feature_scores_all(experiments_df.iloc[:, :4], filtered_outcomes_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scores as npy\n",
    "np.save('./data/output/feature_scores_60k_4outcomes.npy', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save global scores as npy\n",
    "np.save('./data/output/global_feature_scores_60k_4outcomes.npy', global_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_global = global_scores.T\n",
    "# Rename the columns\n",
    "scores_global.columns = ['Elasticity of Marginal Utility of Consumption', 'Inequality Aversion', 'Pure rate of Social Time Preference', 'SSP RCP Scenario']\n",
    "#Rearrange the columns pure rate of social time preference, inequality aversion, elasticity of marginal utility of consumption\n",
    "scores_global = scores_global[['SSP RCP Scenario', 'Pure rate of Social Time Preference', 'Inequality Aversion', 'Elasticity of Marginal Utility of Consumption']]\n",
    "\n",
    "# Set up figure size to be as square as possible\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "# Create a heatmap without annotations\n",
    " \n",
    "sns.heatmap(scores_global, annot=True, cmap='flare', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_scores = scores.T\n",
    "#Drop the first row\n",
    "# processed_scores = processed_scores.iloc[1:]\n",
    "# Rename the columns\n",
    "processed_scores.columns = ['Elasticity of Marginal Utility of Consumption', 'Inequality Aversion', 'Pure rate of Social Time Preference','SSP RCP Scenario']\n",
    "\n",
    "# Rearrange the columns - pure rate of social time preference, inequality aversion, elasticity of marginal utility of consumption\n",
    "processed_scores = processed_scores[['SSP RCP Scenario', 'Pure rate of Social Time Preference', 'Inequality Aversion', 'Elasticity of Marginal Utility of Consumption']]\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assuming 'df' is your DataFrame\n",
    "\n",
    "# Set up figure size to be as square as possible\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "# Create a heatmap without annotations\n",
    "sns.heatmap(processed_scores, cmap=\"flare\",  annot=False, ax=ax) #square=True,\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assuming 'df' is your DataFrame\n",
    "\n",
    "# Melt your DataFrame to make it suitable for Seaborn's boxplot function\n",
    "processed_scores_df_melted = processed_scores.melt()\n",
    "\n",
    "# Set color palette to match with Heatmap\n",
    "palette = sns.color_palette(\"flare\", as_cmap=True)\n",
    "\n",
    "# Create a figure and set its size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a boxplot\n",
    "sns.boxplot(x='variable', y='value', data=processed_scores_df_melted, palette=\"flare\").set_title('Boxplot for Parameters')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Remove the box around the plot\n",
    "sns.despine()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damages at 2300 and welfare \n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "damage_array = combined_damages[:, :, 285] #285 -2300 # 85 - 2100\n",
    "\n",
    "# Convert the numpy array to a pandas dataframe, use region names\n",
    "damage_df = pd.DataFrame(damage_array, columns = regions_str)\n",
    "\n",
    "# Convert dataframe to long-form\n",
    "damage_df_long = damage_df.melt(var_name='Regions', value_name='Damages')\n",
    "\n",
    "# Create boxplot\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(x='Regions', y='Damages', data=damage_df_long)\n",
    "plt.xticks(rotation=90)     # rotate x labels for better visibility\n",
    "plt.title('Damage distribution across regions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_range_df = damage_df.max() - damage_df.min()\n",
    "# Plot the damage range as bar plot\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(x=regions_str, height=damage_range_df)\n",
    "plt.xticks(rotation=90)     # rotate x labels for better visibility\n",
    "plt.title('Damage range across regions')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize ranges to the interval [0, 1]\n",
    "normalized_range_df = (damage_range_df - damage_range_df.min()) / (damage_range_df.max() - damage_range_df.min())\n",
    "\n",
    "# Plot the normalized damage range as bar plot\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(x=regions_str, height=normalized_range_df)\n",
    "plt.xticks(rotation=90)     # rotate x labels for better visibility\n",
    "plt.title('Normalized damage range across regions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# load region to country mapping from JSON file\n",
    "with open(\"data/input/rice50_regions_dict.json\") as json_file:\n",
    "    region_to_country = json.load(json_file)\n",
    "\n",
    "# Create a new dataframe from the mapping\n",
    "mapping_df = pd.DataFrame(\n",
    "    list(region_to_country.items()),\n",
    "    columns=['Region', 'CountryCode']\n",
    ")\n",
    "\n",
    "# Merge the mapping dataframe with the range of damages dataframe\n",
    "country_damage_df = pd.merge(\n",
    "    mapping_df,\n",
    "    normalized_range_df.reset_index().rename(columns={'index': 'Region', 0: 'Damage'}),\n",
    "    on='Region'\n",
    ")\n",
    "\n",
    "# # Convert the string of country codes to a list\n",
    "# country_damage_df['CountryCode'] = country_damage_df['CountryCode'].str.split(',')\n",
    "\n",
    "# # Then explode\n",
    "# country_damage_df = country_damage_df.explode('CountryCode')\n",
    "# Create a dataframe\n",
    "new_country_damage_list = []\n",
    "\n",
    "for idx, row in country_damage_df.iterrows():\n",
    "    for country in row['CountryCode']:\n",
    "        new_country_damage_list.append([country, row['Damage']])\n",
    "\n",
    "# Convert list of lists to DataFrame\n",
    "new_country_damage_df = pd.DataFrame(new_country_damage_list, columns=['CountryCode', 'Damage'])\n",
    "\n",
    "# Save the dataframe as a csv file\n",
    "new_country_damage_df.to_csv('data/output/damage_range_normalized_by_country.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Rise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_temp has shape (8000, 286) Need to convert the timestep to year\n",
    "# Load the data\n",
    "from src.model_time import TimeHorizon\n",
    "\n",
    "time_horizon = TimeHorizon(start_year=2015, end_year=2300, data_timestep=5, timestep=1)\n",
    "list_of_years = time_horizon.model_time_horizon\n",
    "\n",
    "# Use list of years as column labels for the combined_temp array\n",
    "combined_temp_df = pd.DataFrame(combined_temp, columns=list_of_years)\n",
    "\n",
    "# Use time_horizon.timestep_to_year(timestep_count, timestep) to convert combined_temp timesteps to year\n",
    "# Convert the column to year\n",
    "#combined_temp_year = time_horizon.timestep_to_year(combined_temp.shape[1], combined_temp)\n",
    "\n",
    "# Calculate the year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Setting style and size\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Calculate percentiles and median\n",
    "p_0 = np.percentile(combined_temp_df, 0, axis=0)\n",
    "p_5 = np.percentile(combined_temp_df, 5, axis=0)\n",
    "p_16 = np.percentile(combined_temp_df, 16, axis=0)\n",
    "p_84 = np.percentile(combined_temp_df, 84, axis=0)\n",
    "p_95 = np.percentile(combined_temp_df, 95, axis=0)\n",
    "p_100 = np.percentile(combined_temp_df, 100, axis=0)\n",
    "median = np.median(combined_temp_df, axis=0)\n",
    "\n",
    "# Plot percentiles as bands\n",
    "plt.fill_between(combined_temp_df.columns, p_0, p_100, color='red', alpha=0.3)\n",
    "plt.fill_between(combined_temp_df.columns, p_5, p_95, color='red', alpha=0.2)\n",
    "plt.fill_between(combined_temp_df.columns, p_16, p_84, color='red', alpha=0.5)\n",
    "\n",
    "# Plot median\n",
    "plt.plot(combined_temp_df.columns, median, color='red')\n",
    "\n",
    "\n",
    "# Access the current Axes instance on the current figure:\n",
    "ax = plt.gca()\n",
    "\n",
    "# Remove top and right border\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "  \n",
    "# Remove top and right ticks\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature Rise')\n",
    "# plt.title('Time series plot of Atmospheric Temperature Rise')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Setting style and size\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "combined_global_damages = np.sum(combined_damages, axis=1)\n",
    "\n",
    "combined_global_damages_df = pd.DataFrame(combined_global_damages, columns=list_of_years)\n",
    "\n",
    "# Calculate percentiles and median\n",
    "p_0 = np.percentile(combined_global_damages_df, 0, axis=0)\n",
    "p_5 = np.percentile(combined_global_damages_df, 5, axis=0)\n",
    "p_16 = np.percentile(combined_global_damages_df, 16, axis=0)\n",
    "p_84 = np.percentile(combined_global_damages_df, 84, axis=0)\n",
    "p_95 = np.percentile(combined_global_damages_df, 95, axis=0)\n",
    "p_100 = np.percentile(combined_global_damages_df, 100, axis=0)\n",
    "median = np.median(combined_global_damages_df, axis=0)\n",
    "\n",
    "# Plot percentiles as bands\n",
    "plt.fill_between(combined_global_damages_df.columns, p_0, p_100, color='green', alpha=0.3)\n",
    "plt.fill_between(combined_global_damages_df.columns, p_5, p_95, color='green', alpha=0.2)\n",
    "plt.fill_between(combined_global_damages_df.columns, p_16, p_84, color='green', alpha=0.5)\n",
    "\n",
    "# Plot median\n",
    "plt.plot(combined_global_damages_df.columns, median, color='green')\n",
    "\n",
    "# # Labeling\n",
    "# plt.title('Time series plot of Atmospheric Temperature Rise')\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('Temperature Rise')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# Access the current Axes instance on the current figure:\n",
    "ax = plt.gca()\n",
    "\n",
    "# Remove top and right border\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "  \n",
    "# Remove top and right ticks\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Economic Damages in Trillion $')\n",
    "plt.title('Time series plot of Economic Damages')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your region_list is already decoded from the previous step\n",
    "welfare_df = pd.DataFrame(welfare_utilitarian_regional_combined_1000, columns=regions_str)\n",
    "\n",
    "# Define range\n",
    "lower_bound = -30000\n",
    "upper_bound = 30000\n",
    "\n",
    "# Filter the rows\n",
    "filtered_df = welfare_df[(welfare_df >= lower_bound) & (welfare_df <= upper_bound)]\n",
    "\n",
    "# Now, filtered_df will contain only the rows where all values in that row are within the defined range.\n",
    "# Since pandas drop the rows while maintaining the original index, you need to reset it\n",
    "\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Melt the dataframe from wide to long format\n",
    "filtered_df_long = filtered_df.melt(var_name='Regions', value_name='Welfare')\n",
    "\n",
    "# Plot using seaborn\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(x='Regions', y='Welfare', data=filtered_df_long)\n",
    "plt.xticks(rotation=90)     # rotate x labels for better visibility \n",
    "plt.title('Welfare distribution across regions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_index = filtered_df.dropna()\n",
    "filtered_index = filtered_index.index\n",
    "\n",
    "filtered_experiments = combined_experiments[filtered_index]\n",
    "# Keep first 3 columns of filtered_experiments\n",
    "#filtered_experiments = filtered_experiments[:, :3]\n",
    "filtered_experiments = pd.DataFrame(filtered_experiments, columns=['elasticity_of_marginal_utility_of_consumption', 'inequality_aversion', 'pure_rate_of_social_time_preference', 'scenario', 'policy', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "welfare_utilitarian_combined = pd.DataFrame(welfare_utilitarian_combined_1000, columns=['aggregated_welfare'])\n",
    "welfare_utilitarian_filtered = welfare_utilitarian_combined.iloc[filtered_index]\n",
    "filtered_welfare = filtered_df.dropna()\n",
    "region_idx = 43\n",
    "combined_welfare_normative = pd.concat([filtered_experiments, filtered_welfare.iloc[:,region_idx], welfare_utilitarian_filtered], axis=1)\n",
    "#filtered_experiments_df = pd.DataFrame(filtered_experiments, )\n",
    "sns.pairplot(combined_welfare_normative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_idx = 43\n",
    "filtered_outcomes = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_str[0]\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "# Create a empty dataframe to store the feature scores of shape 57, 3\n",
    "scores = pd.DataFrame(np.zeros((57, 3)), columns=['elasticity_of_marginal_utility_of_consumption', 'inequality_aversion', 'pure_rate_of_social_time_preference'])\n",
    "# Loop throught he regions_str list\n",
    "for region_idx in range(57):\n",
    "    print(region_idx)\n",
    "    # Create a dictionary to store the filtered outcomes\n",
    "    filtered_outcomes[regions_str[region_idx]] = filtered_welfare.iloc[:,region_idx]\n",
    "    filtered_outcomes[regions_str[region_idx]] = filtered_welfare.iloc[:,region_idx]\n",
    "    scores = feature_scoring.get_feature_scores_all(filtered_experiments.iloc[:, :3], filtered_outcomes)\n",
    "    \n",
    "sns.heatmap(scores, annot=True, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scores dataframe as a pickle file\n",
    "import pickle\n",
    "with open('./data/output/sensitivity_scores_1000_57reg.pkl', 'wb') as f:\n",
    "    pickle.dump(scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.analysis import feature_scoring\n",
    "# Create a empty dataframe to store the feature scores of shape 57, 3\n",
    "scores_global = pd.DataFrame(np.zeros((57, 3)), columns=['Elasticity of Marginal Utility of Consumption', 'Inequality Aversion', 'Pure rate of Social Time Preference'])\n",
    "# Loop throught he regions_str list\n",
    "filtered_outcomes_global = {}\n",
    "# for region_idx in range(57):\n",
    "#     print(region_idx)\n",
    "#     # Create a dictionary to store the filtered outcomes\n",
    "#     filtered_outcomes[regions_str[region_idx]] = filtered_welfare.iloc[:,region_idx]\n",
    "#     filtered_outcomes[regions_str[region_idx]] = filtered_welfare.iloc[:,region_idx]\n",
    "    \n",
    "filtered_outcomes_global['Global'] = welfare_utilitarian_filtered\n",
    "scores_global = feature_scoring.get_feature_scores_all(filtered_experiments.iloc[:, :3], filtered_outcomes_global) \n",
    "\n",
    "scores_global = scores_global.T\n",
    "# Rename the columns\n",
    "scores_global.columns = ['Elasticity of Marginal Utility of Consumption', 'Inequality Aversion', 'Pure rate of Social Time Preference']\n",
    "#Rearrange the columns pure rate of social time preference, inequality aversion, elasticity of marginal utility of consumption\n",
    "scores_global = scores_global[['Pure rate of Social Time Preference', 'Inequality Aversion', 'Elasticity of Marginal Utility of Consumption']]\n",
    "\n",
    "# Set up figure size to be as square as possible\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "# Create a heatmap without annotations\n",
    " \n",
    "sns.heatmap(scores_global, annot=True, cmap='flare', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_scores = scores.T\n",
    "#Drop the first row\n",
    "processed_scores = processed_scores.iloc[1:]\n",
    "# Rename the columns\n",
    "processed_scores.columns = ['Elasticity of Marginal Utility of Consumption', 'Inequality Aversion', 'Pure rate of Social Time Preference']\n",
    "\n",
    "# Rearrange the columns - pure rate of social time preference, inequality aversion, elasticity of marginal utility of consumption\n",
    "processed_scores = processed_scores[['Pure rate of Social Time Preference', 'Inequality Aversion', 'Elasticity of Marginal Utility of Consumption']]\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assuming 'df' is your DataFrame\n",
    "\n",
    "# Set up figure size to be as square as possible\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "# Create a heatmap without annotations\n",
    "sns.heatmap(processed_scores, cmap=\"flare\",  annot=False, ax=ax) #square=True,\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assuming 'df' is your DataFrame\n",
    "\n",
    "# Melt your DataFrame to make it suitable for Seaborn's boxplot function\n",
    "processed_scores_df_melted = processed_scores.melt()\n",
    "\n",
    "# Set color palette to match with Heatmap\n",
    "palette = sns.color_palette(\"flare\", as_cmap=True)\n",
    "\n",
    "# Create a figure and set its size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a boxplot\n",
    "sns.boxplot(x='variable', y='value', data=processed_scores_df_melted, palette=\"flare\").set_title('Boxplot for Parameters')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Remove the box around the plot\n",
    "sns.despine()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a new dataframe\n",
    "df = pd.DataFrame()\n",
    "df['Global'] = welfare_utilitarian\n",
    "df['Region1'] = welfare_utilitarian_regional[54,:] # adjust this for different regions\n",
    "\n",
    "# Create scatterplot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='Global', y='Region1', data=df)\n",
    "plt.title('Scatterplot of Global vs Region1')\n",
    "plt.xlabel('Global')\n",
    "plt.ylabel('Region1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a new dataframe\n",
    "df = pd.DataFrame()\n",
    "df['Global'] = welfare_utilitarian\n",
    "df['Region1'] = welfare_utilitarian_regional[43,:] # adjust this for different regions\n",
    "\n",
    "# Create scatterplot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='Global', y='Region1', data=df)\n",
    "plt.title('Scatterplot of Global vs Region1')\n",
    "plt.xlabel('Global')\n",
    "plt.ylabel('Region1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation of each region to the global value \n",
    "correlation_list = [df['Global'].corr(df['Region'+str(i)]) for i in range(1, 58)]\n",
    "\n",
    "# build a dataframe of correlations\n",
    "corr_df = pd.DataFrame(correlation_list, columns=['Correlation'])\n",
    "corr_df['Region'] = ['Region'+str(i) for i in range(1, 58)]\n",
    "\n",
    "# Make the barplot\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.barplot(x='Region', y='Correlation', data=corr_df)\n",
    "plt.title('Correlation of Regional Utility and Global Utility')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of damage_df for all the regions across 8000 scenarios\n",
    "\n",
    "# Calculate the mean of damage_df for all the regions across 8000 scenarios\n",
    "mean_damage_df = damage_df.mean(axis=0)\n",
    "\n",
    "\n",
    "# Plot a barplot of mean damage for all the regions\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(x=regions_str, height=mean_damage_df)\n",
    "plt.xticks(rotation=90)     # rotate x labels for better visibility\n",
    "plt.title('Mean damage across regions')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# load region to country mapping from JSON file\n",
    "with open(\"data/input/rice50_regions_dict.json\") as json_file:\n",
    "    region_to_country = json.load(json_file)\n",
    "\n",
    "# Create a new dataframe from the mapping\n",
    "mapping_df = pd.DataFrame(\n",
    "    list(region_to_country.items()),\n",
    "    columns=['Region', 'CountryCode']\n",
    ")\n",
    "\n",
    "# Merge the mapping dataframe with the range of damages dataframe\n",
    "country_damage_df = pd.merge(\n",
    "    mapping_df,\n",
    "    mean_damage_df.reset_index().rename(columns={'index': 'Region', 0: 'Damage'}),\n",
    "    on='Region'\n",
    ")\n",
    "\n",
    "# # Convert the string of country codes to a list\n",
    "# country_damage_df['CountryCode'] = country_damage_df['CountryCode'].str.split(',')\n",
    "\n",
    "# # Then explode\n",
    "# country_damage_df = country_damage_df.explode('CountryCode')\n",
    "# Create a dataframe\n",
    "new_country_damage_list = []\n",
    "\n",
    "for idx, row in country_damage_df.iterrows():\n",
    "    for country in row['CountryCode']:\n",
    "        new_country_damage_list.append([country, row['Damage']])\n",
    "\n",
    "# Convert list of lists to DataFrame\n",
    "new_country_damage_df = pd.DataFrame(new_country_damage_list, columns=['CountryCode', 'Damage'])\n",
    "\n",
    "# Save the dataframe as a csv file\n",
    "new_country_damage_df.to_csv('data/output/damage_mean_by_country.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export new_country_damage_df as a excel file\n",
    "new_country_damage_df.to_excel('data/output/damage_mean_by_country.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert region_to_country dictionary to a dataframe\n",
    "region_to_country_df = pd.DataFrame(region_to_country.items(), columns=['Region', 'CountryCode'])\n",
    "# The country codes are separated by comma, convert them to columns\n",
    "region_to_country_df = region_to_country_df.explode('CountryCode')\n",
    "\n",
    "#Convert to excel file. Merge the region names if it is repeating to one cell\n",
    "region_to_country_df.to_excel('data/output/region_to_country.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks Test for EMODPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the architecture of neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size, first_layer_size, hidden_layers, hidden_layer_size, weights=None, biases=None):\n",
    "        super(Net, self).__init__()\n",
    "        self.first_layer = nn.Linear(input_size, first_layer_size)\n",
    "        \n",
    "        if weights is not None and biases is not None:\n",
    "            self.first_layer.weight = nn.Parameter(torch.Tensor(weights[0]))\n",
    "            self.first_layer.bias = nn.Parameter(torch.Tensor(biases[0]))\n",
    "            \n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(hidden_layers - 1):\n",
    "            hidden_layer = nn.Linear(first_layer_size, hidden_layer_size)\n",
    "            if weights is not None and biases is not None:\n",
    "                hidden_layer.weight = nn.Parameter(torch.Tensor(weights[i+1]))\n",
    "                hidden_layer.bias = nn.Parameter(torch.Tensor(biases[i+1]))\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "            \n",
    "            first_layer_size = hidden_layer_size\n",
    "\n",
    "        self.last_layer = nn.Linear(first_layer_size, output_size)\n",
    "\n",
    "        if weights is not None and biases is not None:\n",
    "            self.last_layer.weight = nn.Parameter(torch.Tensor(weights[-1]))\n",
    "            self.last_layer.bias = nn.Parameter(torch.Tensor(biases[-1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.first_layer(x), 0.1)\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = F.leaky_relu(hidden_layer(x), 0.1)\n",
    "        x = torch.sigmoid(self.last_layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size, first_layer_size, hidden_layers, hidden_layer_size, weights=None, biases=None):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        if hidden_layers > 0:\n",
    "            self.first_layer = nn.Linear(input_size, first_layer_size)\n",
    "            if weights is not None and biases is not None:\n",
    "                self.first_layer.weight = nn.Parameter(torch.Tensor(weights[0]))\n",
    "                self.first_layer.bias = nn.Parameter(torch.Tensor(biases[0]))\n",
    "            \n",
    "            self.hidden_layers = nn.ModuleList()\n",
    "            for i in range(hidden_layers - 1):\n",
    "                hidden_layer = nn.Linear(first_layer_size, hidden_layer_size)\n",
    "                if weights is not None and biases is not None:\n",
    "                    hidden_layer.weight = nn.Parameter(torch.Tensor(weights[i+1]))\n",
    "                    hidden_layer.bias = nn.Parameter(torch.Tensor(biases[i+1]))\n",
    "                self.hidden_layers.append(hidden_layer)\n",
    "                first_layer_size = hidden_layer_size\n",
    "\n",
    "            self.last_layer = nn.Linear(first_layer_size, output_size)\n",
    "            if weights is not None and biases is not None:\n",
    "                self.last_layer.weight = nn.Parameter(torch.Tensor(weights[-1]))\n",
    "                self.last_layer.bias = nn.Parameter(torch.Tensor(biases[-1]))\n",
    "\n",
    "        else:\n",
    "            self.last_layer = nn.Linear(input_size, output_size)\n",
    "            if weights is not None and biases is not None:\n",
    "                self.last_layer.weight = nn.Parameter(torch.Tensor(weights[0]))\n",
    "                self.last_layer.bias = nn.Parameter(torch.Tensor(biases[0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.hidden_layers:\n",
    "            x = F.leaky_relu(self.first_layer(x), 0.1)\n",
    "            for hidden_layer in self.hidden_layers:\n",
    "                x = F.leaky_relu(hidden_layer(x), 0.1)\n",
    "            x = torch.sigmoid(self.last_layer(x))\n",
    "        else:\n",
    "            x = torch.sigmoid(self.last_layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# # Create a 57 by 57 matrix of value 0.5\n",
    "# weights = np.full((57, 57), 0.5)\n",
    "# # Create a shape (57) matrix of value 0.5\n",
    "# biases = np.full((57), 0.5)\n",
    "# Assumption - MOEA provides these values\n",
    "layer_1_weights = np.full((57, 57), 0.5)  # replace with actual value from MOEA\n",
    "layer_2_weights = np.full((57, 57), 0.5)  # replace with actual value from MOEA\n",
    "\n",
    "layer_1_biases = np.full((57), 0.0)  # replace with actual value from MOEA\n",
    "layer_2_biases = np.full((57), 0.0)  # replace with actual value from MOEA\n",
    "\n",
    "# Stack them into lists\n",
    "weights = [layer_1_weights, layer_2_weights]\n",
    "biases = [layer_1_biases, layer_2_biases]\n",
    "\n",
    "model = Net(input_size=57, output_size=57, first_layer_size=57, hidden_layers=1, hidden_layer_size=57, weights=weights, biases=biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a 1 by 57 numpy array of 0.5s\n",
    "input_data = np.full((1, 57), 0.2)\n",
    "\n",
    "# Convert the numpy array to a torch tensor\n",
    "input_data_tensor = torch.Tensor(input_data)\n",
    "\n",
    "# Pass the tensor through the model\n",
    "output = model(input_data_tensor)\n",
    "\n",
    "output = output.detach().numpy()\n",
    "\n",
    "# Print the output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
